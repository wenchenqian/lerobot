# æ•´ä½“æ¡†æ¶

![img_1.png](img_1.png)
æ•´ä½“æ¡†æ¶å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè®­ç»ƒå’Œæ¨ç†å„è‡ªæœ‰å…¶æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶å¤¹ä¸‹æœ‰å¯¹åº”çš„è®­ç»ƒå’Œæ¨ç†apiï¼Œç„¶åcoreæ–‡ä»¶å¤¹å†…æœ‰è¿™æœ€æ ¸å¿ƒçš„ä¸€äº›ç»„ä»¶çš„å®ç°ï¼Œå¦‚optimizerã€modelsã€Transformerå’Œå„ç§å¹¶è¡Œå’Œåˆ†å¸ƒå¼é€šè®¯çš„åº“ã€‚

# å¹¶è¡Œåˆå§‹åŒ–

megatronçš„å¹¶è¡Œåˆå§‹åŒ–è°ƒç”¨çš„æ˜¯initialize_megatron()ï¼Œå†…éƒ¨ä¼šè°ƒç”¨initialize_model_parallel()ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹è¿™ä¸ªå‡½æ•°æ˜¯å¦‚ä½•å¯¹DPã€PPã€TPã€CPã€EPè¿›è¡Œé€šè®¯åŸŸåˆå§‹åŒ–çš„ï¼š

```
""" å‡½æ•°çš„å‚æ•°å¤ªå¤šäº†ï¼Œè¿™é‡Œçœç•¥ """
def initialize_model_parallel(...) -> None:
    """ åˆå§‹åŒ–DPå¹¶è¡Œç»„ """
    ... # å…¨å±€å˜é‡è·å–
    for ranks in generator_wrapper('dp'):
        group = torch.distributed.new_group(ranks, timeout=timeout, pg_options=get_nccl_options('dp', nccl_comm_cfgs))
        group_gloo = torch.distributed.new_group(ranks, timeout=timeout, backend="gloo")
        if rank in ranks:
            """ 
            è¿™é‡Œçš„ifåˆ¤æ–­çš„é€»è¾‘æ˜¯ï¼šåªæœ‰æˆ‘è¿™ä¸ªè®­ç»ƒè¿›ç¨‹çš„rankåœ¨è¿™ä¸ªgroupé‡Œæˆ‘æ‰ä¼šæŠŠæˆ‘è¿™ä¸ªè®­ç»ƒè¿›ç¨‹çš„å¹¶è¡Œé€šä¿¡ç»„è®¾ç½®ä¸ºåˆšæ‰åˆ›å»ºå‡ºæ¥çš„groupã€‚
            è€Œè¿™ä¸ªgroupçš„ç±»å‹æ˜¯pytorchçš„ProcessGroupå¯¹è±¡ï¼Œå¯¹äºä¸‹é¢æ‰€æœ‰çš„å¹¶è¡Œç»„çš„åˆ›å»ºéƒ½æ˜¯èµ°çš„è¿™ä¸ªé€»è¾‘ã€‚
            """
            _DATA_PARALLEL_GROUP = group
            _DATA_PARALLEL_GROUP_GLOO = group_gloo
            _DATA_PARALLEL_GLOBAL_RANKS = ranks
  
    """ åˆå§‹åŒ–DP-CPå¹¶è¡Œç»„ï¼Œç”±äºCPçš„å¹¶è¡Œé€»è¾‘åŸå› ï¼ŒDPå’ŒCPçš„åˆ†ç»„å¯ä»¥å…±ç”¨ä¸€ä¸ªé€šä¿¡ç»„ """
    for ranks_with_cp in generator_wrapper('dp-cp'):
        group_with_cp = torch.distributed.new_group(ranks_with_cp, timeout=timeout, pg_options=get_nccl_options('dp_cp', nccl_comm_cfgs))
        group_with_cp_gloo = torch.distributed.new_group(ranks_with_cp, timeout=timeout, backend="gloo")
        if rank in ranks_with_cp:
             # do samething
   
    ...

    """ åˆå§‹åŒ–CPå¹¶è¡Œç»„ """
    ... # å…¨å±€å˜é‡è·å–
    for ranks in generator_wrapper('cp'):
        group = torch.distributed.new_group(ranks, timeout=timeout, pg_options=get_nccl_options('cp', nccl_comm_cfgs))
        if rank in ranks:
            # do samething

    """ åˆå§‹åŒ–DPåŸŸå¹¶è¡Œç»„ï¼Œè¿™ä¸ªgroupå†…åŒ…å«äº†ä¸€ä¸ªå®Œæ•´æ¨¡å‹å‚æ•°æ‰€éœ€çš„rankå· """
    ... # å…¨å±€å˜é‡è·å–
    for ranks in generator_wrapper('tp-pp'):
        group = torch.distributed.new_group(ranks, timeout=timeout, pg_options=get_nccl_options('mp', nccl_comm_cfgs))
        if rank in ranks:
            # do samething
    ...
   
    """ åˆå§‹åŒ–TPå¹¶è¡Œç»„ """
    ... # å…¨å±€å˜é‡è·å–
    for ranks in generator_wrapper('tp'):
        group = torch.distributed.new_group(ranks, timeout=timeout, pg_options=get_nccl_options('tp', nccl_comm_cfgs))
        if rank in ranks:
            # do samething

    """ åˆå§‹åŒ–PPå¹¶è¡Œç»„ """
    ... # å…¨å±€å˜é‡è·å–
    for ranks in generator_wrapper('pp'):
        group = torch.distributed.new_group(ranks, timeout=timeout, pg_options=get_nccl_options('pp', nccl_comm_cfgs))
        if rank in ranks:
            if _PIPELINE_MODEL_PARALLEL_GROUP is None:
                _PIPELINE_MODEL_PARALLEL_GROUP = group
                _PIPELINE_GLOBAL_RANKS = ranks
            elif isinstance(_PIPELINE_GLOBAL_RANKS[0], list):
                _PIPELINE_MODEL_PARALLEL_GROUP.append(group)
                _PIPELINE_GLOBAL_RANKS.append(ranks)
            else:
                _PIPELINE_MODEL_PARALLEL_GROUP = [_PIPELINE_MODEL_PARALLEL_GROUP, group]
                _PIPELINE_GLOBAL_RANKS = [_PIPELINE_GLOBAL_RANKS, ranks]

        embedding_ranks = get_embedding_ranks(ranks)
        group = torch.distributed.new_group(embedding_ranks, timeout=timeout, pg_options=get_nccl_options('embd', nccl_comm_cfgs))
        if rank in embedding_ranks:
            # do samething

        position_embedding_ranks = get_position_embedding_ranks(ranks)
        group = torch.distributed.new_group(...)
        if rank in position_embedding_ranks:
            # do samething
   
    """ åˆå§‹åŒ–TP+CPå¹¶è¡Œç»„ï¼Œè¿™ä¸ªå¹¶è¡Œç»„ç”¨äºæå‡æ•ˆç‡ï¼Œå› ä¸ºAttentionå±‚å‰TPå’ŒCPå¹¶è¡Œç»„éƒ½ä¼šè°ƒç”¨all-gatherï¼Œæ‰€ä»¥å¯ä»¥åˆå¹¶ """
    ... # å…¨å±€å˜é‡è·å–
    for ranks in generator_wrapper('tp-cp'):
        group = torch.distributed.new_group(ranks, timeout=timeout, pg_options=get_nccl_options('tp_cp', nccl_comm_cfgs))
        if rank in ranks:
           # do samething
  
    ... """ EPï¼ŒTP+EPç­‰ç­‰ """ 

    _set_global_memory_buffer()
```

### Megatron å¦‚ä½•åˆ†ç»„ï¼Ÿâ€”â€” ä»¥ TP=2, PP=2, DP=2 ä¸ºä¾‹ï¼ˆå…± 8 GPUï¼‰

#### ğŸ“Œ æ­¥éª¤ 1ï¼šæŒ‰ PP åˆ’åˆ† â€”â€” 2 ä¸ªæµæ°´ stage

* Stage 0: GPU [0, 1, 2, 3]
* Stage 1: GPU [4, 5, 6, 7]

#### ğŸ“Œ æ­¥éª¤ 2ï¼šåœ¨æ¯ä¸ª stage å†…ï¼ŒæŒ‰ DP åˆ’åˆ† â€”â€” 2 ä¸ªæ•°æ®å¹¶è¡Œç»„

* Stage 0:
  * DP Group 0: [0, 2]
  * DP Group 1: [1, 3]
* Stage 1:
  * DP Group 0: [4, 6]
  * DP Group 1: [5, 7]

#### ğŸ“Œ æ­¥éª¤ 3ï¼šåœ¨æ¯ä¸ª DP ç»„å†…ï¼ŒæŒ‰ TP åˆ’åˆ† â€”â€” 2 ä¸ªå¼ é‡å¹¶è¡Œç»„

* Stage 0, DP Group 0: [0, 2] â†’ TP ç»„å°±æ˜¯ [0, 2]ï¼ˆTP=2ï¼Œåˆšå¥½2ä¸ªï¼‰
* Stage 0, DP Group 1: [1, 3] â†’ TP ç»„æ˜¯ [1, 3]
* Stage 1, DP Group 0: [4, 6] â†’ TP ç»„ [4, 6]
* Stage 1, DP Group 1: [5, 7] â†’ TP ç»„ [5, 7]

## data\_iteratoråˆ›å»º

åœ¨å½“å‰ç»å¤§å¤šæ•°åœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬éƒ½æ˜¯ç”¨çš„gptæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¯¹åº”çš„megatronä¹Ÿæœ‰`GPTDataset`ï¼Œæˆ‘ä»¬åœ¨å¯åŠ¨è®­ç»ƒå‰å°±ä¼šåˆ›å»ºå‡º`data_iterator`å’Œ`Dataloader`ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹megatronæ˜¯å¦‚ä½•åˆ›å»ºè¿™äº›å…³é”®ç»„ä»¶çš„

```python
def train_valid_test_datasets_provider(train_val_test_num_samples):
    args = get_args()

    config = core_gpt_dataset_config_from_args(args)

    if config.mock:
        dataset_type = MockGPTDataset
    else:
        dataset_type = GPTDataset   """ ä½¿ç”¨çš„æ•°æ®é›†ç±»å‹ """
    print_rank_0("> building train, validation, and test datasets for GPT ...")

    if args.is_instruction_dataset:
        ...  """ å¾ˆå°‘ç”¨ """
    else:
        """ å…³é”®å‡½æ•° """
        train_ds, valid_ds, test_ds = BlendedMegatronDatasetBuilder(dataset_type, train_val_test_num_samples, is_dataset_built_on_rank, config).build()

    print_rank_0("> finished creating GPT datasets ...")

    return train_ds, valid_ds, test_ds
```

ä¸Šé¢çš„ä»£ç è¿›å…¥åˆ°äº†BlendedMegatronDatasetBuilderå†…è¿›è¡Œæ•°æ®é›†åˆ›å»ºï¼Œè¿™å†…éƒ¨çš„ä»£ç ååˆ†å†—é•¿ï¼Œé€»è¾‘æ¯”è¾ƒå¤æ‚ï¼Œæ•…æ”¾åˆ°è¿›é˜¶å†…å®¹çš„7.1èŠ‚è¿›è¡Œè¯¦ç»†è®²è¿°ã€‚æ¥ä¸‹æ¥ç²—ç•¥è®²è¿°ä¸€ä¸‹data-iteratorçš„åˆ›å»º

```python
def pretrain(...):
    # Initalize and get arguments, timers, and Tensorboard writer.
    initialize_megatron(...) 
    ...
    # Model, optimizer, and learning rate.
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(model_provider, model_type)
    ...
    # Data stuff.
    if args.virtual_pipeline_model_parallel_size is not None:
        train_data_iterator = []
        valid_data_iterator = []
        test_data_iterator = []
        for i in range(len(model)):
            mpu.set_virtual_pipeline_model_parallel_rank(i)
            iterators = build_train_valid_test_data_iterators(
                train_valid_test_dataset_provider)
            train_data_iterator.append(iterators[0])
            valid_data_iterator.append(iterators[1])
            test_data_iterator.append(iterators[2])
    else:
        """ VPPæœªå¯ç”¨æ—¶çš„é€»è¾‘ï¼Œæˆ‘ä»¬å¤§å¤šæ•°æ—¶å€™éƒ½èµ°è¿™é‡Œ """
        train_data_iterator, valid_data_iterator, test_data_iterator = build_train_valid_test_data_iterators(train_valid_test_dataset_provider)
    print_datetime('after dataloaders are built')


def build_train_valid_test_data_iterators(build_train_valid_test_datasets_provider):
    args = get_args()

    """ ä½¿ç”¨æˆ‘ä»¬è¿™ä¸€ç« èŠ‚æœ€å¼€å§‹ç»™å‡ºçš„é‚£ä¸ªdataset providerå‡½æ•°åˆ›å»ºæ•°æ®é›†å’ŒDataloader """
    train_dataloader, valid_dataloader, test_dataloader = build_train_valid_test_data_loaders(build_train_valid_test_datasets_provider)

    # Build iterators.
    dl_type = args.dataloader_type
    assert dl_type in ['single', 'cyclic', 'external']

    def _get_iterator(dataloader_type, dataloader):
        """Return dataset iterator."""
        if dataloader_type == "single":
            return iter(dataloader)
        elif dataloader_type == "cyclic":
            return iter(cyclic_iter(dataloader))
        elif dataloader_type == "external":
            # External dataloader is passed through. User is expected to define how to iterate.
            return dataloader
        else:
            raise RuntimeError("unexpected dataloader type")

    if train_dataloader is not None:
        train_data_iterator = _get_iterator(dl_type, train_dataloader)
    else:
        train_data_iterator = None
    if valid_dataloader is not None:
        valid_data_iterator = _get_iterator(dl_type, valid_dataloader)
    else:
        valid_data_iterator = None
    if test_dataloader is not None:
        test_data_iterator = _get_iterator(dl_type, test_dataloader)
    else:
        test_data_iterator = None
    """ è¿™ä¸ªiteratorå°±æ˜¯å°†DataloaderåŒ…è£…ä¸ºå¯è¿­ä»£çš„å¯¹è±¡ï¼Œä»¥æ–¹ä¾¿åœ¨gpt_forward_stepä¸­ä½¿ç”¨next(data_iterator)è·å¾—æ•°æ® """ 
    return train_data_iterator, valid_data_iterator, test_data_iterator
```

ä»ä¸Šé¢å¯ä»¥çœ‹åˆ°åˆ›å»ºçš„è¿‡ç¨‹ï¼Œå…¶ä¸­Dataloaderçš„åˆ›å»ºæˆ‘è¿™é‡Œçœç•¥ï¼Œå› ä¸ºè¿™é‡Œè¯»è€…ä»¬è‡ªå·±å¯ä»¥å»é˜…è¯»ä¸€ä¸‹ä»£ç ï¼Œå…¶å®å·²ç»å¾ˆå®¹æ˜“å°±èƒ½å¤Ÿä¸²èµ·å¼€å§‹çš„datasetåˆ›å»ºå’Œä¸Šé¢ç»™å‡ºçš„iteratoråˆ›å»ºçš„è¿‡ç¨‹ã€‚

åœ¨Dataloaderåˆ›å»ºçš„å‡½æ•°ä¸­ä¼šå…ˆåˆ›å»ºå‡ºä¸‰ä¸ªdatasetã€trainï¼Œvalidï¼Œtestã€‘ï¼Œç„¶åæ ¹æ®ä¸‰ä¸ªdatasetå„è‡ªåˆ›å»ºå‡ºå¯¹åº”çš„Dataloaderã€è¿™é‡Œçš„Dataloaderå°±æ˜¯pytorchçš„Dataloaderã€‘ã€‚

æœ‰äº†dataloaderä¹‹åæˆ‘ä»¬å°±å¯ä»¥åœ¨è®­ç»ƒä¸­è¿›è¡Œbatchæ•°æ®è¯»å–äº†ï¼Œè¿™é‡Œçš„é€»è¾‘ç¬”è€…æ”¾åœ¨ä¸‹ä¸€ç« çš„é¢„è®­ç»ƒä¸­è®²è¿°ã€‚

# é¢„è®­ç»ƒï¼š

## åŸºäºiterationçš„è®­ç»ƒï¼š

ä¸ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ åŸºäºepochæ¥è®­ç»ƒçš„æ¨¡å¼ä¸åŒï¼ŒLLMå†…æ²¡æœ‰äº†epochçš„æ¦‚å¿µï¼Œåªæœ‰`iteration`çš„æ¦‚å¿µâ€”â€”å³è¿™æ¬¡è®­ç»ƒä¼šè¿›è¡ŒN\*Mä¸ª`forward-backward`æ“ä½œï¼ŒNä¸ª`step`æ“ä½œã€‚ï¼ˆ`N = iteration`ï¼Œ`M = global_batch_size / micro_batch_size`ï¼‰

ä¸‹é¢æˆ‘ä»¬ä»ä»£ç ä¸Šçœ‹çœ‹åŸºäºiterationçš„è®­ç»ƒä»£ç ï¼š

```python
def train(forward_step_func, model, optimizer, opt_param_scheduler, train_data_iterator, valid_data_iterator, process_non_loss_data_func, config):
    args = get_args()
    timers = get_timers()

    # Turn on training mode which enables dropout.
    for model_module in model:
        model_module.train()

    # Tracking loss.
    total_loss_dict = {}

    # Iterations.
    iteration = args.iteration

    ... # Setup some training config params
  
    """ æœ€é‡è¦çš„whileè®­ç»ƒï¼Œé‡Œé¢æ‰§è¡Œiterationæ¬¡train_stepå‡½æ•° """
    num_microbatches = get_num_microbatches()
    while iteration < args.train_iters:
        ... """ æ›´æ–°num microbatchå¤§å° """

        args.curr_iteration = iteration
        """ è°ƒç”¨train_stepè®­ç»ƒä¸€ä¸ªstepã€fwdã€bwdã€optimizer.stepã€‘ """
        loss_dict, skipped_iter, grad_norm, num_zeros_in_grad = \
            train_step(forward_step_func,
                       train_data_iterator,
                       model,
                       optimizer,
                       opt_param_scheduler,
                       config)
        iteration += 1
        batch_size = mpu.get_data_parallel_world_size() * \
                     args.micro_batch_size * \
                     get_num_microbatches()
        args.consumed_train_samples += batch_size
  
        ... """ loggingç›¸å…³ä»£ç  """

        ... """ Evaluation """
  
        ... """ Checkpointing ä¿å­˜æƒé‡æ–‡ä»¶ """ 
  
    ... """ æ‰€æœ‰iterationå®Œæˆä¹‹åçš„é€€å‡ºé€»è¾‘ """

    return iteration, num_floating_point_operations_so_far
```


## train\_stepå‡½æ•°ï¼š

åœ¨megatronä¸­ï¼Œ`forward`å’Œ`backward`å› ä¸ºæµæ°´çº¿å¹¶è¡Œè€Œéœ€è¦å®šåˆ¶ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½åƒåŸå§‹çš„æœºå™¨å­¦ä¹ ä¸€æ ·ç›´æ¥æŠŠinputæ”¾å…¥modelï¼Œç„¶åè°ƒç”¨`loss.backward()`è®¡ç®—æ¢¯åº¦ã€‚åŸå› å°±æ˜¯æ¯å¼ å¡é‡Œçš„modelå…¶å®éƒ½ä¸ä¸€æ ·ï¼Œå¯¹äºè¾“å…¥çš„shapeçš„è¦æ±‚ä¹Ÿä¸ä¸€æ ·ï¼Œ

æ‰€ä»¥æˆ‘ä»¬éœ€è¦åŒ…è£…`forward`çš„inputï¼Œæœ‰å¯èƒ½è¿™ä¸ªinputæ˜¯æœ€å¼€å§‹çš„è¾“å…¥ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯ä¸Šä¸€ä¸ªpipeline stageçš„outputã€‚æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å¯¹äºæµæ°´çº¿å¹¶è¡Œæ¥è¯´`forward`å’Œ`backward`çš„æµç¨‹ï¼š

```python
def train_step(...):
    ...
    """ æ¸…é™¤grad """
    if args.DDP_impl == 'local' and args.use_contiguous_buffers_in_local_ddp:
        for partition in model:
            partition.zero_grad_buffer()
    optimizer.zero_grad()
    ...
  
    """ æ‰§è¡Œå‰å‘ã€åå‘è®¡ç®— """
    forward_backward_func = get_forward_backward_func()  """ è·å¾—forwardå’Œbackwardå‡½æ•°ï¼Œé‡Œé¢ä¼šæ ¹æ®PPçš„è®¾ç½®è¿”å›ä¸åŒçš„å‡½æ•° """
    losses_reduced = forward_backward_func(...) 
    ...
  
    """ å¯¹æ¢¯åº¦æ‰§è¡ŒReduce-Scatteræ“ä½œ """
    optimizer.reduce_model_grads(args, timers)
    ...
  
    """ æ›´æ–°è¯¥DPåŸŸæŒæœ‰çš„æ¢¯åº¦å¯¹åº”çš„éƒ¨åˆ†å‚æ•° """
    timers('optimizer', log_level=1).start(barrier=args.barrier_with_L1_time)
    update_successful, grad_norm, num_zeros_in_grad = optimizer.step(args, timers)
    timers('optimizer').stop()
    ...
  
    """ å¯¹æ›´æ–°åçš„paramæ‰§è¡Œgatheræ“ä½œ """
    if update_successful:
        optimizer.gather_model_params(args, timers)
    ...
  
    """ é€šè¿‡scheduleræ›´æ–°å­¦ä¹ ç‡ """
    if update_successful:
        increment = get_num_microbatches() * args.micro_batch_size * args.data_parallel_size
        opt_param_scheduler.step(increment=increment)
        skipped_iter = 0
    else:
        skipped_iter = 1
    ...
```
åœ¨å°†fwdå’Œbwdä¹‹å‰ï¼Œæˆ‘ä»¬æœ‰å¿…è¦äº†è§£ä¸€ä¸‹global_batch_size, micro_batch_size, DP_sizeå’Œnum_micro_batchesçš„å…³ç³»ï¼š
```python
 self.num_micro_batches = (running_global_batch_size // micro_batch_times_data_parallel_size)  # 16 // (2 * 4) = 2
```
æˆ‘ä»¬åœ¨è®­ç»ƒçš„è„šæœ¬é‡Œä¼šæŒ‡å®šè¿™ä¸¤ä¸ªsizeå‚æ•°ï¼Œç„¶åmegatronä¼šæ ¹æ®DPçš„æ•°é‡è®¡ç®—å‡ºæ¥è¿™ä¸ªnum_micro_batchesçš„å¤§å°ï¼Œè¿™ä¸ªæ•°çš„ç”¨å¤„å¾ˆå¤§ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†fwd-bwdçš„æ—¶å€™å°±ä¼šè®²åˆ°ã€‚
